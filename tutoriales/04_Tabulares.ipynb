{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score,balanced_accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from plotly import express as px\n",
    "\n",
    "#from UA_MDM_LDI_II.tutoriales.utils import plot_confusion_matrix\n",
    "from utils import plot_confusion_matrix\n",
    "\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.artifacts import FileSystemArtifactStore, upload_artifact\n",
    "\n",
    "from joblib import load, dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = './'\n",
    "PATH_TO_TRAIN = os.path.join(BASE_DIR, \"input/petfinder-adoption-prediction/train/train.csv\")\n",
    "PATH_TO_MODELS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/models\")\n",
    "PATH_TO_TEMP_FILES = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_temp_artifacts\")\n",
    "PATH_TO_OPTUNA_ARTIFACTS = os.path.join(BASE_DIR, \"UA_MDM_LDI_II/work/optuna_artifacts\")\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "BATCH_SIZE = 50\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos Tabulares\n",
    "dataset = pd.read_csv(PATH_TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset,\n",
    "                               test_size = TEST_SIZE,\n",
    "                               random_state = SEED,\n",
    "                               stratify = dataset.AdoptionSpeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_feats = [f for f in dataset.columns if dataset[f].dtype=='O']\n",
    "numeric_feats = [f for f in dataset.columns if dataset[f].dtype!='O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Type',\n",
    " 'Age',\n",
    " 'Breed1',\n",
    " 'Breed2',\n",
    " 'Gender',\n",
    " 'Color1',\n",
    " 'Color2',\n",
    " 'Color3',\n",
    " 'MaturitySize',\n",
    " 'FurLength',\n",
    " 'Vaccinated',\n",
    " 'Dewormed',\n",
    " 'Sterilized',\n",
    " 'Health',\n",
    " 'Quantity',\n",
    " 'Fee',\n",
    " 'State',\n",
    " 'VideoAmt',\n",
    " 'PhotoAmt']\n",
    "\n",
    "label = 'AdoptionSpeed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[label]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = params = {\n",
    "                        'objective': 'multiclass',\n",
    "                        'num_class': len(y_train.unique())\n",
    "                        }\n",
    "\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "cohen_kappa_score(y_test,y_pred, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot_confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(y_test,y_test, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(plot_confusion_matrix(y_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_shuffled = shuffle(y_test,\n",
    "                     random_state = 42)\n",
    "\n",
    "\n",
    "dict_map_cerca = {0:1,\n",
    "                  1:2,\n",
    "                  2:3,\n",
    "                  3:4,\n",
    "                  4:3}\n",
    "\n",
    "dict_map_lejos = {0:4,\n",
    "                  1:4,\n",
    "                  2:0,\n",
    "                  3:0,\n",
    "                  4:0}\n",
    "\n",
    "y_cerca = [dict_map_cerca[i] for i in y_test]\n",
    "\n",
    "y_lejos = [dict_map_lejos[i] for i in y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_list =  np.random.rand(len(y_test))\n",
    "\n",
    "kappa_progression = pd.DataFrame()\n",
    "\n",
    "for i in range(101):\n",
    "\n",
    "    y_simulado = [y_test.iloc[sample] if random_list[sample]<i/100 else y_shuffled.iloc[sample] for sample in range(len(y_test))]\n",
    "\n",
    "    y_simulado_cerca = [y_test.iloc[sample] if random_list[sample]<i/100 else y_cerca[sample] for sample in range(len(y_test))]\n",
    "\n",
    "    y_simulado_lejos = [y_test.iloc[sample] if random_list[sample]<i/100 else y_lejos[sample] for sample in range(len(y_test))]\n",
    "\n",
    "\n",
    "    kappa_progression = pd.concat([kappa_progression,\n",
    "                                   pd.DataFrame({'Conocidos':[i],\n",
    "                                                'kappa':cohen_kappa_score(y_test,\n",
    "                                                                        y_simulado,\n",
    "                                                                        weights = 'quadratic'),\n",
    "                                                'kappa_cerca':cohen_kappa_score(y_test,\n",
    "                                                                        y_simulado_cerca,\n",
    "                                                                        weights = 'quadratic'),\n",
    "                                                'kappa_lejos':cohen_kappa_score(y_test,\n",
    "                                                                        y_simulado_lejos,\n",
    "                                                                        weights = 'quadratic'),                                                                        \n",
    "                                                'accuracy':accuracy_score(y_test,\n",
    "                                                                        y_simulado),\n",
    "                                                'balanced_accuracy':balanced_accuracy_score(y_test,\n",
    "                                                                        y_simulado),\n",
    "                                                                        })],\n",
    "                ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(kappa_progression,x='Conocidos',y=['kappa',\n",
    "                                           'kappa_cerca',\n",
    "                                           'kappa_lejos',\n",
    "                                           'accuracy',\n",
    "                                           'balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_simulado_cerca = [y_test.iloc[sample] if random_list[sample]<50/100 else y_cerca[sample] for sample in range(len(y_test))]\n",
    "\n",
    "display(plot_confusion_matrix(y_test,y_simulado_cerca, \n",
    "                              title = \"Kappa \" + str(cohen_kappa_score(y_test,y_simulado_cerca, weights = 'quadratic'))))\n",
    "\n",
    "\n",
    "y_simulado_lejos = [y_test.iloc[sample] if random_list[sample]<50/100 else y_lejos[sample] for sample in range(len(y_test))]\n",
    "\n",
    "display(plot_confusion_matrix(y_test,y_simulado_lejos, \n",
    "                              title = \"Kappa \" + str(cohen_kappa_score(y_test,y_simulado_lejos, weights = 'quadratic'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = params = {\n",
    "                        'objective': 'multiclassova',\n",
    "                        'num_class': len(y_train.unique())\n",
    "                        }\n",
    "\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                      lgb_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = lgb_model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "display(plot_confusion_matrix(y_test,y_pred))\n",
    "\n",
    "{'kappa':cohen_kappa_score(y_test,\n",
    "                y_pred,\n",
    "                weights = 'quadratic'),\n",
    " 'accuracy':accuracy_score(y_test,y_pred),\n",
    " 'balanced_accuracy':balanced_accuracy_score(y_test,y_pred)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial):\n",
    "    lgb_params = {      \n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique()),\n",
    "                        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        } \n",
    "\n",
    "\n",
    "    lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                    label=y_train)\n",
    "\n",
    "\n",
    "    lgb_model = lgb.train(lgb_params,\n",
    "                        lgb_train_dataset)\n",
    "    \n",
    "    return(cohen_kappa_score(y_test,lgb_model.predict(X_test).argmax(axis=1),\n",
    "                             weights = 'quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"04 - LGB Multiclass\",\n",
    "                            load_if_exists=True)\n",
    "study.optimize(lgb_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params =  {      \n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique())} | study.best_params\n",
    "\n",
    "lgb_train_dataset = lgb.Dataset(data=X_train,\n",
    "                                label=y_train)\n",
    "\n",
    "\n",
    "lgb_model = lgb.train(lgb_params,\n",
    "                    lgb_train_dataset)\n",
    "\n",
    "display(plot_confusion_matrix(y_test,lgb_model.predict(X_test).argmax(axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_custom_metric_kappa(dy_pred, dy_true):\n",
    "\n",
    "    metric_name = 'kappa'\n",
    "    value = cohen_kappa_score(dy_true.get_label(),dy_pred.argmax(axis=1),weights = 'quadratic')\n",
    "    is_higher_better = True\n",
    "    return(metric_name, value, is_higher_better)\n",
    "\n",
    "def cv_es_lgb_objective(trial):\n",
    "\n",
    "    lgb_params = {      \n",
    "                        'objective': 'multiclass',\n",
    "                        'verbosity':-1,\n",
    "                        'num_class': len(y_train.unique()),\n",
    "                        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "                        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "                        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "                        } \n",
    "\n",
    "    scores_ensemble = np.zeros((len(y_test),len(y_train.unique())))\n",
    "    score_folds = 0\n",
    "    n_splits = 5\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    for i, (if_index, oof_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        \n",
    "        lgb_if_dataset = lgb.Dataset(data=X_train.iloc[if_index],\n",
    "                                        label=y_train.iloc[if_index],\n",
    "                                        free_raw_data=False)\n",
    "        \n",
    "        lgb_oof_dataset = lgb.Dataset(data=X_train.iloc[oof_index],\n",
    "                                        label=y_train.iloc[oof_index],\n",
    "                                        free_raw_data=False)\n",
    "\n",
    "        lgb_model = lgb.train(lgb_params,\n",
    "                                lgb_if_dataset,\n",
    "                                valid_sets=lgb_oof_dataset,\n",
    "                                callbacks=[lgb.early_stopping(10, verbose=False)],\n",
    "                                feval = lgb_custom_metric_kappa\n",
    "                                )\n",
    "        \n",
    "        scores_ensemble = scores_ensemble + lgb_model.predict(X_test) #prediction!!!!\n",
    "        \n",
    "        score_folds = score_folds + cohen_kappa_score(y_train.iloc[oof_index], \n",
    "                                                            lgb_model.predict(X_train.iloc[oof_index]).argmax(axis=1),weights = 'quadratic')/n_splits\n",
    "\n",
    "\n",
    "    predicted_filename = os.path.join(PATH_TO_TEMP_FILES,f'test_{trial.study.study_name}_{trial.number}.joblib')\n",
    "    predicted_df = test.copy()\n",
    "    predicted_df['pred'] = [scores_ensemble[p,:] for p in range(scores_ensemble.shape[0])]\n",
    "    dump(predicted_df, predicted_filename)\n",
    "    upload_artifact(trial, predicted_filename, artifact_store)    \n",
    "\n",
    "    cm_filename = os.path.join(PATH_TO_TEMP_FILES,f'cm_{trial.study.study_name}_{trial.number}.jpg')\n",
    "    plot_confusion_matrix(y_test,scores_ensemble.argmax(axis=1)).write_image(cm_filename)\n",
    "    upload_artifact(trial, cm_filename, artifact_store)\n",
    "\n",
    "    test_score = cohen_kappa_score(y_test,scores_ensemble.argmax(axis=1),weights = 'quadratic')\n",
    "    trial.set_user_attr(\"test_score\", test_score)\n",
    "\n",
    "    return(score_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_store = FileSystemArtifactStore(base_path=PATH_TO_OPTUNA_ARTIFACTS)\n",
    "\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                            storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "                            study_name=\"04 - LGB Multiclass CV\",\n",
    "                            load_if_exists = True)\n",
    "\n",
    "study.optimize(cv_es_lgb_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1967, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 924, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlite3.OperationalError: no such table: version_info\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\", line 72, in _create_scoped_session\n",
      "    yield session\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\", line 1042, in _init_version_info_model\n",
      "    version_info = models.VersionInfoModel.find(session)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna\\storages\\_rdb\\models.py\", line 578, in find\n",
      "    version_info = session.query(cls).one_or_none()\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\orm\\query.py\", line 2754, in one_or_none\n",
      "    return self._iter().one_or_none()  # type: ignore\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\orm\\query.py\", line 2827, in _iter\n",
      "    result: Union[ScalarResult[_T], Result[_T]] = self.session.execute(\n",
      "                                                  ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 2351, in execute\n",
      "    return self._execute_internal(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\orm\\session.py\", line 2236, in _execute_internal\n",
      "    result: Result[Any] = compile_state_cls.orm_execute_statement(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\orm\\context.py\", line 293, in orm_execute_statement\n",
      "    result = conn.execute(\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1418, in execute\n",
      "    return meth(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py\", line 515, in _execute_on_connection\n",
      "    return connection._execute_clauseelement(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1640, in _execute_clauseelement\n",
      "    ret = self._execute_context(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1846, in _execute_context\n",
      "    return self._exec_single_context(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1986, in _exec_single_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 2353, in _handle_dbapi_exception\n",
      "    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\base.py\", line 1967, in _exec_single_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 924, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: version_info\n",
      "[SQL: SELECT version_info.version_info_id AS version_info_version_info_id, version_info.schema_version AS version_info_schema_version, version_info.library_version AS version_info_library_version \n",
      "FROM version_info]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Scripts\\optuna-dashboard.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna_dashboard\\_cli.py\", line 119, in main\n",
      "    storage = get_storage(args.storage, storage_class=args.storage_class)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna_dashboard\\_storage_url.py\", line 59, in get_storage\n",
      "    return guess_storage_from_url(storage)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna_dashboard\\_storage_url.py\", line 84, in guess_storage_from_url\n",
      "    return get_rdb_storage(storage_url)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna_dashboard\\_storage_url.py\", line 91, in get_rdb_storage\n",
      "    return RDBStorage(storage_url, skip_compatibility_check=True, skip_table_creation=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\", line 231, in __init__\n",
      "    self._version_manager = _VersionManager(self.url, self.engine, self.scoped_session)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\", line 1037, in __init__\n",
      "    self._init_version_info_model()\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\", line 1041, in _init_version_info_model\n",
      "    with _create_scoped_session(self.scoped_session, True) as session:\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\Usuario\\.conda\\envs\\ldi2\\Lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\", line 90, in _create_scoped_session\n",
      "    raise optuna.exceptions.StorageInternalError(message) from e\n",
      "optuna.exceptions.StorageInternalError: An exception is raised during the commit. This typically happens due to invalid data in the commit, e.g. exceeding max length. \n"
     ]
    }
   ],
   "source": [
    "!optuna-dashboard sqlite:///db.sqlite3 --artifact-dir ../work/optuna_artifacts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
